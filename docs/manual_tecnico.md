# âš™ï¸ Manual TÃ©cnico - Pipeline de PrevisÃ£o de Acidentes

## ğŸ“Œ Objetivo

Este pipeline processa dados pÃºblicos de acidentes rodoviÃ¡rios, realiza a engenharia de features e treina um modelo de machine learning para prever risco de acidentes por trecho, horÃ¡rio e condiÃ§Ãµes climÃ¡ticas.

---

## ğŸ“‚ Estrutura do Projeto

src/
â”œâ”€â”€ data_collection.py # Coleta e leitura de dados brutos
â”œâ”€â”€ data_processing.py # Limpeza e padronizaÃ§Ã£o dos dados
â”œâ”€â”€ ml_pipeline.py # CriaÃ§Ã£o de variÃ¡vieis para ML, treinamento e validaÃ§Ã£o do modelo
â”œâ”€â”€ postgres_insert.py # InserÃ§Ã£o dos dados no PostgreSQL
â””â”€â”€ dashboard.py # Interface com Streamlit


---

## ğŸ”„ Pipeline ETL

### 1. `data_collection.py`
- LÃª os dados da PRF (acidentes.csv)
- Pode integrar com APIs no futuro

### 2. `data_processing.py`
- Corrige tipos e formataÃ§Ãµes
- Remove valores invÃ¡lidos ou nulos com `when(...).otherwise(...)`
- Converte campos para `DateType` / `DoubleType` no PySpark


### 3. `ml_pipeline.py`
- Gera variÃ¡veis como:
  - `hist_acidentes_km`
  - `semana_dia`, `hora`
- Junta com os dados originais por `br`, `km`
- Usa o algoritmo `GBTClassifier` (MLlib/Spark)
- Realiza prÃ©-processamento com Pipeline (indexaÃ§Ã£o, vetorizaÃ§Ã£o)
- Treina o modelo com 80% dos dados
- Avalia com AUC-ROC e Precision@K
- Agrupa os 50 trechos mais crÃ­ticos por risco mÃ©dio previsto
- Salva as previsÃµes no PostgreSQL e gera um PDF com o relatÃ³rio

---

## ğŸ§ª Banco de Dados

- PostgreSQL
    - Usado para armazenar os resultados e previsÃµes
        - Tabelas envolvidas:
        - `acidentes_processados_*`
        - `acidentes_preditos`
        - `trechos_criticos`
    - Usado para armazenar usuÃ¡rios e cÃ³digos de autenticaÃ§Ã£o
        - `mfa_codes`,
        - `users`
---

## ğŸ§° Tecnologias

- Spark 3.5.0 e Streamlit (via Docker)
- Pandas, NumPy, Scikit-learn, Seaborn, Matplotlib, Requests, Reportlib
- PostgreSQL 15.13
- Docker Compose para orquestraÃ§Ã£o local
